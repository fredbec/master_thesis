
@article{cramer_evaluation_nodate,
	title = {Evaluation of individual and ensemble probabilistic forecasts of {COVID}-19 mortality in the {US}},
	abstract = {Short-term probabilistic forecasts of the trajectory of the COVID-19 pandemic in the United States have served as a visible and important communication channel between the scientific modeling community and both the general public and decision-makers. Forecasting models
provide specific, quantitative, and evaluable predictions that inform short-term decisions such as
healthcare staffing needs, school closures, and allocation of medical supplies. Starting in April 2020, the US COVID-19 Forecast Hub (https://covid19forecasthub.org/) collected,
disseminated, and synthesized tens of millions of specific predictions from more than 90 different academic, industry, and independent research groups. A multi-model ensemble
forecast that combined predictions from dozens of different research groups every week provided the most consistently accurate probabilistic forecasts of incident deaths due to COVID-19 at the state and national level from April 2020 through October 2021. The performance of 27 individual models that submitted complete forecasts of COVID-19 deaths consistently throughout this year showed high variability in forecast skill across time, geospatial units, and forecast horizons. Two-thirds of the models evaluated showed better accuracy than a naïve
baseline model. Forecast accuracy degraded as models made predictions further into the future,
with probabilistic error at a 20-week horizon 3-5 times larger than when predicting at a 1-week horizon. This project underscores the role that collaboration and active coordination between governmental public health agencies, academic modeling teams, and industry partners can play in developing modern modeling capabilities to support local, state, and federal response to outbreaks.},
	author = {Cramer, Estee and Ray, Evan and Lopez, Velma and Bracher, Johannes},
	keywords = {C19\_forecast\_eval},
}

@article{sherratt_draft_nodate,
	title = {({Draft}) {Predictive} performance of multi-model ensemble forecasts of {COVID}-19 across {European} nations},
	abstract = {Background: Short-term forecasts of infectious disease burden can contribute to situational awareness and aid capacity planning. Best practice in other fields and recent insights in infectious disease epidemiology suggest that predictive performance of such forecasts can be enhanced by combining multiple models into an ensemble. Here we report on the performance of ensembles created from over 40 models in predicting COVID-19 cases and deaths across Europe between 08 March and 15 November 2021.
Methods: We used open-source tools to develop a public European COVID-19 Forecast Hub.We invited groups globally to contribute weekly forecasts for COVID-19 cases and deaths over the next one to four weeks. Forecasts were submitted using standardised quantiles of the predictive distribution. Each week we created an ensemble forecast, where each predictive quantile was calculated as the equally-weighted average (initially the mean and then the median from the 26th of July) of all individual models’ predictive quantiles. We retrospectively explored alternative methods for ensemble forecasts, including weighted averages based on models’ past predictive performance. The performance of the ensembles was compared to individual models and a baseline model of no change using pairwise comparison of the Weighted Interval Score (WIS).
Results: Over 36 weeks we collected and combined 43 forecast models for 32 countries. We found a weekly ensemble had among the most reliable performances across countries over time, with more accurate predictions for reported cases and deaths than a simple baseline for 67\% and 91\% of possible forecast targets respectively. Relative ensemble performance declined with increasing forecast horizon when forecasting cases but remained stable for 4 weeks for incident death forecasts. Among several choices of ensemble methods we found that the most influential and best choice was to use a median average of models instead of using the mean, regardless of methods of weighting component forecast models.},
	author = {Sherratt, Katharine and Gruson, Hugo},
}

@article{reich_collaborative_2019,
	title = {A collaborative multiyear, multimodel assessment of seasonal influenza forecasting in the {United} {States}},
	abstract = {Influenza infects an estimated 9–35 million individuals each year in
the United States and is a contributing cause for between 12,000
and 56,000 deaths annually. Seasonal outbreaks of influenza are
common in temperate regions of the world, with highest incidence
typically occurring in colder and drier months of the year. Realtime
forecasts of influenza transmission can inform public health
response to outbreaks.We present the results of a multiinstitution
collaborative effort to standardize the collection and evaluation
of forecasting models for influenza in the United States for the
2010/2011 through 2016/2017 influenza seasons. For these seven
seasons, we assembled weekly real-time forecasts of seven targets
of public health interest from 22 different models. We compared
forecast accuracy of each model relative to a historical baseline seasonal
average. Across all regions of the United States, over half of
the models showed consistently better performance than the historical
baseline when forecasting incidence of influenza-like illness
1 wk, 2 wk, and 3 wk ahead of available data and when forecasting
the timing and magnitude of the seasonal peak. In some
regions, delays in data reporting were strongly and negatively
associated with forecast accuracy. More timely reporting and an
improved overall accessibility to novel and traditional data sources
are needed to improve forecasting accuracy and its integration
with real-time public health decision making.},
	author = {Reich, Nicolas and Brooks, Logan},
	year = {2019},
}

@article{funk_short-term_nodate,
	title = {Short-term forecasts to inform the response to the {Covid}-19 epidemic in the {UK}},
	author = {Funk, Sebastian and Abbott, Sam},
}

@article{funk_assessing_nodate,
	title = {Assessing the performance of real-time epidemic forecasts: {A} case study of {Ebola} in the {Western} {Area} region of {Sierra} {Leone}, 2014-15},
	abstract = {Real-time forecasts based on mathematical models can inform critical decision-making during infectious disease outbreaks. Yet, epidemic forecasts are rarely evaluated during or after the event, and there is little guidance on the best metrics for assessment. Here, we propose an evaluation approach that disentangles different components of forecasting ability using metrics that separately assess the calibration, sharpness and bias of forecasts. This makes it possible to assess not just how close a forecast was to reality but also how well uncertainty has been quantified. We used this approach to analyse the performance of weekly forecasts we generated in real time for Western Area, Sierra Leone, during the 2013–16 Ebola epidemic in West Africa. We investigated a range of forecast model variants based on the model fits generated at the time with a semi-mechanistic model, and found that good probabilistic calibration was achievable at short time horizons of one or two weeks ahead but model predictions were increasingly unreliable at longer forecasting horizons.
This suggests that forecasts may have been of good enough quality to inform decision making based on predictions a few weeks ahead of time but not longer, reflecting the high level of uncertainty in the processes driving the trajectory of the epidemic. Comparing forecasts based on the semi-mechanistic model to simpler null models showed that the best semimechanistic model variant performed better than the null models with respect to probabilistic calibration, and that this would have been identified from the earliest stages of the outbreak. As forecasts become a routine part of the toolkit in public health, standards for evaluation of performance will be important for assessing quality and improving credibility of mathematical models, and for elucidating difficulties and trade-offs when aiming to make the most useful and reliable forecasts.},
	author = {Funk, Sebastian and Camacho, Anton},
}

@article{taylor_combining_2021,
	title = {Combining probabilistic forecasts of {COVID}-19 mortality in the {United} {States}},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221721005609},
	doi = {10.1016/j.ejor.2021.06.044},
	language = {en},
	urldate = {2022-04-12},
	journal = {European Journal of Operational Research},
	author = {Taylor, James W. and Taylor, Kathryn S.},
	month = jun,
	year = {2021},
	keywords = {US-ForecastHub, Ensemble Methods},
	pages = {S0377221721005609},
}

@article{holmdahl_wrong_2020,
	title = {Wrong but {Useful} — {What} {Covid}-19 {Epidemiologic} {Models} {Can} and {Cannot} {Tell} {Us}},
	volume = {383},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMp2016822},
	doi = {10.1056/NEJMp2016822},
	language = {en},
	number = {4},
	urldate = {2022-04-12},
	journal = {New England Journal of Medicine},
	author = {Holmdahl, Inga and Buckee, Caroline},
	month = jul,
	year = {2020},
	pages = {303--305},
}

@article{bracher_pre-registered_2021,
	title = {A pre-registered short-term forecasting study of {COVID}-19 in {Germany} and {Poland} during the second wave},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-25207-0},
	doi = {10.1038/s41467-021-25207-0},
	abstract = {Abstract
            Disease modelling has had considerable policy impact during the ongoing COVID-19 pandemic, and it is increasingly acknowledged that combining multiple models can improve the reliability of outputs. Here we report insights from ten weeks of collaborative short-term forecasting of COVID-19 in Germany and Poland (12 October–19 December 2020). The study period covers the onset of the second wave in both countries, with tightening non-pharmaceutical interventions (NPIs) and subsequently a decay (Poland) or plateau and renewed increase (Germany) in reported cases. Thirteen independent teams provided probabilistic real-time forecasts of COVID-19 cases and deaths. These were reported for lead times of one to four weeks, with evaluation focused on one- and two-week horizons, which are less affected by changing NPIs. Heterogeneity between forecasts was considerable both in terms of point predictions and forecast spread. Ensemble forecasts showed good relative performance, in particular in terms of coverage, but did not clearly dominate single-model predictions. The study was preregistered and will be followed up in future phases of the pandemic.},
	language = {en},
	number = {1},
	urldate = {2022-04-19},
	journal = {Nature Communications},
	author = {Bracher, J. and Wolffram, D. and Deuschel, J. and Görgen, K. and Ketterer, J. L. and Ullrich, A. and Abbott, S. and Barbarossa, M. V. and Bertsimas, D. and Bhatia, S. and Bodych, M. and Bosse, N. I. and Burgard, J. P. and Castro, L. and Fairchild, G. and Fuhrmann, J. and Funk, S. and Gogolewski, K. and Gu, Q. and Heyder, S. and Hotz, T. and Kheifetz, Y. and Kirsten, H. and Krueger, T. and Krymova, E. and Li, M. L. and Meinke, J. H. and Michaud, I. J. and Niedzielewski, K. and Ożański, T. and Rakowski, F. and Scholz, M. and Soni, S. and Srivastava, A. and Zieliński, J. and Zou, D. and Gneiting, T. and Schienle, M. and {List of Contributors by Team} and {CovidAnalytics-DELPHI} and Li, Michael Lingzhi and Bertsimas, Dimitris and Bouardi, Hamza Tazi and Lami, Omar Skali and Soni, Saksham and {epiforecasts-EpiExpert and epiforecasts-EpiNow2} and Abbott, Sam and Bosse, Nikos I. and Funk, Sebastian and {FIAS FZJ-Epi1Ger} and Barbarossa, Maria Vittoria and Fuhrmann, Jan and Meinke, Jan H. and {German and Polish Forecast Hub Coordination Team} and Bracher, Johannes and Deuschel, Jannik and Gneiting, Tilmann and Görgen, Konstantin and Ketterer, Jakob and Schienle, Melanie and Ullrich, Alexander and Wolffram, Daniel and {ICM-agentModel} and Górski, Łukasz and Gruziel-Słomka, Magdalena and Kaczorek, Artur and Moszyński, Antoni and Niedzielewski, Karol and Nowosielski, Jedrzej and Radwan, Maciej and Rakowski, Franciszek and Semeniuk, Marcin and Zieliński, Jakub and Bartczuk, Rafał and Kisielewski, Jan and {Imperial-ensemble2} and Bhatia, Sangeeta and {ITWW-county repro} and Biecek, Przemyslaw and Bezborodov, Viktor and Bodych, Marcin and Krueger, Tyll and Burgard, Jan Pablo and Heyder, Stefan and Hotz, Thomas and {LANL-GrowthRate} and Osthus, Dave A. and Michaud, Isaac J. and Castro, Lauren and Fairchild, Geoffrey and {LeipzigIMISE-SECIR} and Kheifetz, Yuri and Kirsten, Holger and Scholz, Markus and {MIMUW-StochSEIR} and Gambin, Anna and Gogolewski, Krzysztof and Miasojedow, Błażej and Szczurek, Ewa and Rabczenko, Daniel and Rosińska, Magdalena and {MOCOS-agent1} and Bawiec, Marek and Bodych, Marcin and Ożański, Tomasz and Pabjan, Barbara and Rafajłlowicz, Ewaryst and Skubalska-Rafajłowicz, Ewa and Rafajłowicz, Wojciech and Migalska, Agata and Szczurek, Ewa and {SDSC ISG-TrendModel} and Flahault, Antoine and Manetti, Elisa and Choirat, Christine and Haro, Benjamin Bejar and Krymova, Ekaterina and Lee, Gavin and Obozinski, Guillaume and Sun, Tao and Thanou, Dorina and {UCLA-SuEIR} and Gu, Quanquan and Xu, Pan and Chen, Jinghui and Wang, Lingxiao and Zou, Difan and Zhang, Weitong and {USC-SIkJalpha} and Srivastava, Ajitesh and Prasanna, Viktor K. and Xu, Frost Tianjian},
	month = dec,
	year = {2021},
	pages = {5173},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\HHXNQYZ5\\Bracher et al. - 2021 - A pre-registered short-term forecasting study of C.pdf:application/pdf},
}

@article{bracher_evaluating_2021,
	title = {Evaluating epidemic forecasts in an interval format},
	volume = {17},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1008618},
	doi = {10.1371/journal.pcbi.1008618},
	abstract = {For practical reasons, many forecasts of case, hospitalization, and death counts in the context of the current Coronavirus Disease 2019 (COVID-19) pandemic are issued in the form of central predictive intervals at various levels. This is also the case for the forecasts collected in the
              COVID-19 Forecast Hub
              (
              https://covid19forecasthub.org/
              ). Forecast evaluation metrics like the logarithmic score, which has been applied in several infectious disease forecasting challenges, are then not available as they require full predictive distributions. This article provides an overview of how established methods for the evaluation of quantile and interval forecasts can be applied to epidemic forecasts in this format. Specifically, we discuss the computation and interpretation of the weighted interval score, which is a proper score that approximates the continuous ranked probability score. It can be interpreted as a generalization of the absolute error to probabilistic forecasts and allows for a decomposition into a measure of sharpness and penalties for over- and underprediction.},
	language = {en},
	number = {2},
	urldate = {2022-04-20},
	journal = {PLOS Computational Biology},
	author = {Bracher, Johannes and Ray, Evan L. and Gneiting, Tilmann and Reich, Nicholas G.},
	editor = {Pitzer, Virginia E.},
	month = feb,
	year = {2021},
	pages = {e1008618},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\7RMRT9JP\\Bracher et al. - 2021 - Evaluating epidemic forecasts in an interval forma.pdf:application/pdf},
}

@article{bosse_comparing_2021,
	title = {Comparing human and model-based forecasts of {COVID}-19 in {Germany} and {Poland}},
	abstract = {Forecasts based on epidemiological modelling have played an important role in shaping public policy throughout the COVID-19 pandemic. This modelling combines knowledge about infectious disease dynamics with the subjective opinion of the researcher who develops and refines the model and often also adjusts model outputs. Developing a forecast model is difficult, resource- and time-consuming. It is therefore worth asking what modelling is able to add beyond the subjective opinion of the researcher alone. To investigate this, we analysed different real-time forecasts of cases of and deaths from COVID-19 in Germany and Poland over a 1-4 week horizon submitted to the German and Polish Forecast Hub. We compared crowd forecasts elicited from researchers and volunteers, against a) forecasts from two semi-mechanistic models based on common epidemiological assumptions and b) the ensemble of all other models submitted to the Forecast Hub. We found crowd forecasts, despite being overconfident, to outperform all other methods across all forecast horizons when forecasting cases (weighted interval score relative to the Hub ensemble 2 weeks ahead: 0.89). Forecasts based on computational models performed comparably better when predicting deaths (rel. WIS 1.26), suggesting that epidemiological modelling and human judgement can complement each other in important ways.},
	author = {Bosse, Nikos and Abbott, Sam},
	year = {2021},
}

@article{yamana_superensemble_2016,
	title = {Superensemble forecasts of dengue outbreaks},
	volume = {13},
	issn = {1742-5689, 1742-5662},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2016.0410},
	doi = {10.1098/rsif.2016.0410},
	abstract = {In recent years, a number of systems capable of predicting future infectious disease incidence have been developed. As more of these systems are operationalized, it is important that the forecasts generated by these different approaches be formally reconciled so that individual forecast error and bias are reduced. Here we present a first example of such multi-system, or superensemble, forecast. We develop three distinct systems for predicting dengue, which are applied retrospectively to forecast outbreak characteristics in San Juan, Puerto Rico. We then use Bayesian averaging methods to combine the predictions from these systems and create superensemble forecasts. We demonstrate that on average, the superensemble approach produces more accurate forecasts than those made from any of the individual forecasting systems.},
	language = {en},
	number = {123},
	urldate = {2022-04-28},
	journal = {Journal of The Royal Society Interface},
	author = {Yamana, Teresa K. and Kandula, Sasikiran and Shaman, Jeffrey},
	month = oct,
	year = {2016},
	pages = {20160410},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\45JV4ZFG\\Yamana et al. - 2016 - Superensemble forecasts of dengue outbreaks.pdf:application/pdf},
}
