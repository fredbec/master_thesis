
@article{cramer_evaluation_2022,
	title = {Evaluation of individual and ensemble probabilistic forecasts of {COVID}-19 mortality in the {US}},
	abstract = {Short-term probabilistic forecasts of the trajectory of the COVID-19 pandemic in the United States have served as a visible and important communication channel between the scientific modeling community and both the general public and decision-makers. Forecasting models
provide specific, quantitative, and evaluable predictions that inform short-term decisions such as
healthcare staffing needs, school closures, and allocation of medical supplies. Starting in April 2020, the US COVID-19 Forecast Hub (https://covid19forecasthub.org/) collected,
disseminated, and synthesized tens of millions of specific predictions from more than 90 different academic, industry, and independent research groups. A multi-model ensemble
forecast that combined predictions from dozens of different research groups every week provided the most consistently accurate probabilistic forecasts of incident deaths due to COVID-19 at the state and national level from April 2020 through October 2021. The performance of 27 individual models that submitted complete forecasts of COVID-19 deaths consistently throughout this year showed high variability in forecast skill across time, geospatial units, and forecast horizons. Two-thirds of the models evaluated showed better accuracy than a naïve
baseline model. Forecast accuracy degraded as models made predictions further into the future,
with probabilistic error at a 20-week horizon 3-5 times larger than when predicting at a 1-week horizon. This project underscores the role that collaboration and active coordination between governmental public health agencies, academic modeling teams, and industry partners can play in developing modern modeling capabilities to support local, state, and federal response to outbreaks.},
	author = {Cramer, Estee and Ray, Evan and Lopez, Velma and Bracher, Johannes},
	year = {2022},
	keywords = {C19\_forecast\_eval, fix\_citation},
}

@article{sherratt_draft_nodate,
	title = {({Draft}) {Predictive} performance of multi-model ensemble forecasts of {COVID}-19 across {European} nations},
	abstract = {Background: Short-term forecasts of infectious disease burden can contribute to situational awareness and aid capacity planning. Best practice in other fields and recent insights in infectious disease epidemiology suggest that predictive performance of such forecasts can be enhanced by combining multiple models into an ensemble. Here we report on the performance of ensembles created from over 40 models in predicting COVID-19 cases and deaths across Europe between 08 March and 15 November 2021.
Methods: We used open-source tools to develop a public European COVID-19 Forecast Hub.We invited groups globally to contribute weekly forecasts for COVID-19 cases and deaths over the next one to four weeks. Forecasts were submitted using standardised quantiles of the predictive distribution. Each week we created an ensemble forecast, where each predictive quantile was calculated as the equally-weighted average (initially the mean and then the median from the 26th of July) of all individual models’ predictive quantiles. We retrospectively explored alternative methods for ensemble forecasts, including weighted averages based on models’ past predictive performance. The performance of the ensembles was compared to individual models and a baseline model of no change using pairwise comparison of the Weighted Interval Score (WIS).
Results: Over 36 weeks we collected and combined 43 forecast models for 32 countries. We found a weekly ensemble had among the most reliable performances across countries over time, with more accurate predictions for reported cases and deaths than a simple baseline for 67\% and 91\% of possible forecast targets respectively. Relative ensemble performance declined with increasing forecast horizon when forecasting cases but remained stable for 4 weeks for incident death forecasts. Among several choices of ensemble methods we found that the most influential and best choice was to use a median average of models instead of using the mean, regardless of methods of weighting component forecast models.},
	author = {Sherratt, Katharine and Gruson, Hugo},
}

@article{reich_collaborative_2019,
	title = {A collaborative multiyear, multimodel assessment of seasonal influenza forecasting in the {United} {States}},
	abstract = {Influenza infects an estimated 9–35 million individuals each year in
the United States and is a contributing cause for between 12,000
and 56,000 deaths annually. Seasonal outbreaks of influenza are
common in temperate regions of the world, with highest incidence
typically occurring in colder and drier months of the year. Realtime
forecasts of influenza transmission can inform public health
response to outbreaks.We present the results of a multiinstitution
collaborative effort to standardize the collection and evaluation
of forecasting models for influenza in the United States for the
2010/2011 through 2016/2017 influenza seasons. For these seven
seasons, we assembled weekly real-time forecasts of seven targets
of public health interest from 22 different models. We compared
forecast accuracy of each model relative to a historical baseline seasonal
average. Across all regions of the United States, over half of
the models showed consistently better performance than the historical
baseline when forecasting incidence of influenza-like illness
1 wk, 2 wk, and 3 wk ahead of available data and when forecasting
the timing and magnitude of the seasonal peak. In some
regions, delays in data reporting were strongly and negatively
associated with forecast accuracy. More timely reporting and an
improved overall accessibility to novel and traditional data sources
are needed to improve forecasting accuracy and its integration
with real-time public health decision making.},
	author = {Reich, Nicolas and Brooks, Logan},
	year = {2019},
}

@article{funk_short-term_nodate,
	title = {Short-term forecasts to inform the response to the {Covid}-19 epidemic in the {UK}},
	author = {Funk, Sebastian and Abbott, Sam},
}

@article{funk_assessing_nodate,
	title = {Assessing the performance of real-time epidemic forecasts: {A} case study of {Ebola} in the {Western} {Area} region of {Sierra} {Leone}, 2014-15},
	abstract = {Real-time forecasts based on mathematical models can inform critical decision-making during infectious disease outbreaks. Yet, epidemic forecasts are rarely evaluated during or after the event, and there is little guidance on the best metrics for assessment. Here, we propose an evaluation approach that disentangles different components of forecasting ability using metrics that separately assess the calibration, sharpness and bias of forecasts. This makes it possible to assess not just how close a forecast was to reality but also how well uncertainty has been quantified. We used this approach to analyse the performance of weekly forecasts we generated in real time for Western Area, Sierra Leone, during the 2013–16 Ebola epidemic in West Africa. We investigated a range of forecast model variants based on the model fits generated at the time with a semi-mechanistic model, and found that good probabilistic calibration was achievable at short time horizons of one or two weeks ahead but model predictions were increasingly unreliable at longer forecasting horizons.
This suggests that forecasts may have been of good enough quality to inform decision making based on predictions a few weeks ahead of time but not longer, reflecting the high level of uncertainty in the processes driving the trajectory of the epidemic. Comparing forecasts based on the semi-mechanistic model to simpler null models showed that the best semimechanistic model variant performed better than the null models with respect to probabilistic calibration, and that this would have been identified from the earliest stages of the outbreak. As forecasts become a routine part of the toolkit in public health, standards for evaluation of performance will be important for assessing quality and improving credibility of mathematical models, and for elucidating difficulties and trade-offs when aiming to make the most useful and reliable forecasts.},
	author = {Funk, Sebastian and Camacho, Anton},
}

@article{taylor_combining_2021,
	title = {Combining probabilistic forecasts of {COVID}-19 mortality in the {United} {States}},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221721005609},
	doi = {10.1016/j.ejor.2021.06.044},
	language = {en},
	urldate = {2022-04-12},
	journal = {European Journal of Operational Research},
	author = {Taylor, James W. and Taylor, Kathryn S.},
	month = jun,
	year = {2021},
	keywords = {US-ForecastHub, Ensemble Methods},
	pages = {S0377221721005609},
}

@article{holmdahl_wrong_2020,
	title = {Wrong but {Useful} — {What} {Covid}-19 {Epidemiologic} {Models} {Can} and {Cannot} {Tell} {Us}},
	volume = {383},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMp2016822},
	doi = {10.1056/NEJMp2016822},
	language = {en},
	number = {4},
	urldate = {2022-04-12},
	journal = {New England Journal of Medicine},
	author = {Holmdahl, Inga and Buckee, Caroline},
	month = jul,
	year = {2020},
	pages = {303--305},
}

@article{bracher_pre-registered_2021,
	title = {A pre-registered short-term forecasting study of {COVID}-19 in {Germany} and {Poland} during the second wave},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-25207-0},
	doi = {10.1038/s41467-021-25207-0},
	abstract = {Abstract
            Disease modelling has had considerable policy impact during the ongoing COVID-19 pandemic, and it is increasingly acknowledged that combining multiple models can improve the reliability of outputs. Here we report insights from ten weeks of collaborative short-term forecasting of COVID-19 in Germany and Poland (12 October–19 December 2020). The study period covers the onset of the second wave in both countries, with tightening non-pharmaceutical interventions (NPIs) and subsequently a decay (Poland) or plateau and renewed increase (Germany) in reported cases. Thirteen independent teams provided probabilistic real-time forecasts of COVID-19 cases and deaths. These were reported for lead times of one to four weeks, with evaluation focused on one- and two-week horizons, which are less affected by changing NPIs. Heterogeneity between forecasts was considerable both in terms of point predictions and forecast spread. Ensemble forecasts showed good relative performance, in particular in terms of coverage, but did not clearly dominate single-model predictions. The study was preregistered and will be followed up in future phases of the pandemic.},
	language = {en},
	number = {1},
	urldate = {2022-04-19},
	journal = {Nature Communications},
	author = {Bracher, J. and Wolffram, D. and Deuschel, J. and Görgen, K. and Ketterer, J. L. and Ullrich, A. and Abbott, S. and Barbarossa, M. V. and Bertsimas, D. and Bhatia, S. and Bodych, M. and Bosse, N. I. and Burgard, J. P. and Castro, L. and Fairchild, G. and Fuhrmann, J. and Funk, S. and Gogolewski, K. and Gu, Q. and Heyder, S. and Hotz, T. and Kheifetz, Y. and Kirsten, H. and Krueger, T. and Krymova, E. and Li, M. L. and Meinke, J. H. and Michaud, I. J. and Niedzielewski, K. and Ożański, T. and Rakowski, F. and Scholz, M. and Soni, S. and Srivastava, A. and Zieliński, J. and Zou, D. and Gneiting, T. and Schienle, M. and {List of Contributors by Team} and {CovidAnalytics-DELPHI} and Li, Michael Lingzhi and Bertsimas, Dimitris and Bouardi, Hamza Tazi and Lami, Omar Skali and Soni, Saksham and {epiforecasts-EpiExpert and epiforecasts-EpiNow2} and Abbott, Sam and Bosse, Nikos I. and Funk, Sebastian and {FIAS FZJ-Epi1Ger} and Barbarossa, Maria Vittoria and Fuhrmann, Jan and Meinke, Jan H. and {German and Polish Forecast Hub Coordination Team} and Bracher, Johannes and Deuschel, Jannik and Gneiting, Tilmann and Görgen, Konstantin and Ketterer, Jakob and Schienle, Melanie and Ullrich, Alexander and Wolffram, Daniel and {ICM-agentModel} and Górski, Łukasz and Gruziel-Słomka, Magdalena and Kaczorek, Artur and Moszyński, Antoni and Niedzielewski, Karol and Nowosielski, Jedrzej and Radwan, Maciej and Rakowski, Franciszek and Semeniuk, Marcin and Zieliński, Jakub and Bartczuk, Rafał and Kisielewski, Jan and {Imperial-ensemble2} and Bhatia, Sangeeta and {ITWW-county repro} and Biecek, Przemyslaw and Bezborodov, Viktor and Bodych, Marcin and Krueger, Tyll and Burgard, Jan Pablo and Heyder, Stefan and Hotz, Thomas and {LANL-GrowthRate} and Osthus, Dave A. and Michaud, Isaac J. and Castro, Lauren and Fairchild, Geoffrey and {LeipzigIMISE-SECIR} and Kheifetz, Yuri and Kirsten, Holger and Scholz, Markus and {MIMUW-StochSEIR} and Gambin, Anna and Gogolewski, Krzysztof and Miasojedow, Błażej and Szczurek, Ewa and Rabczenko, Daniel and Rosińska, Magdalena and {MOCOS-agent1} and Bawiec, Marek and Bodych, Marcin and Ożański, Tomasz and Pabjan, Barbara and Rafajłlowicz, Ewaryst and Skubalska-Rafajłowicz, Ewa and Rafajłowicz, Wojciech and Migalska, Agata and Szczurek, Ewa and {SDSC ISG-TrendModel} and Flahault, Antoine and Manetti, Elisa and Choirat, Christine and Haro, Benjamin Bejar and Krymova, Ekaterina and Lee, Gavin and Obozinski, Guillaume and Sun, Tao and Thanou, Dorina and {UCLA-SuEIR} and Gu, Quanquan and Xu, Pan and Chen, Jinghui and Wang, Lingxiao and Zou, Difan and Zhang, Weitong and {USC-SIkJalpha} and Srivastava, Ajitesh and Prasanna, Viktor K. and Xu, Frost Tianjian},
	month = dec,
	year = {2021},
	pages = {5173},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\HHXNQYZ5\\Bracher et al. - 2021 - A pre-registered short-term forecasting study of C.pdf:application/pdf},
}

@article{bracher_evaluating_2021,
	title = {Evaluating epidemic forecasts in an interval format},
	volume = {17},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1008618},
	doi = {10.1371/journal.pcbi.1008618},
	abstract = {For practical reasons, many forecasts of case, hospitalization, and death counts in the context of the current Coronavirus Disease 2019 (COVID-19) pandemic are issued in the form of central predictive intervals at various levels. This is also the case for the forecasts collected in the
              COVID-19 Forecast Hub
              (
              https://covid19forecasthub.org/
              ). Forecast evaluation metrics like the logarithmic score, which has been applied in several infectious disease forecasting challenges, are then not available as they require full predictive distributions. This article provides an overview of how established methods for the evaluation of quantile and interval forecasts can be applied to epidemic forecasts in this format. Specifically, we discuss the computation and interpretation of the weighted interval score, which is a proper score that approximates the continuous ranked probability score. It can be interpreted as a generalization of the absolute error to probabilistic forecasts and allows for a decomposition into a measure of sharpness and penalties for over- and underprediction.},
	language = {en},
	number = {2},
	urldate = {2022-04-20},
	journal = {PLOS Computational Biology},
	author = {Bracher, Johannes and Ray, Evan L. and Gneiting, Tilmann and Reich, Nicholas G.},
	editor = {Pitzer, Virginia E.},
	month = feb,
	year = {2021},
	pages = {e1008618},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\7RMRT9JP\\Bracher et al. - 2021 - Evaluating epidemic forecasts in an interval forma.pdf:application/pdf},
}

@article{bosse_comparing_2021,
	title = {Comparing human and model-based forecasts of {COVID}-19 in {Germany} and {Poland}},
	abstract = {Forecasts based on epidemiological modelling have played an important role in shaping public policy throughout the COVID-19 pandemic. This modelling combines knowledge about infectious disease dynamics with the subjective opinion of the researcher who develops and refines the model and often also adjusts model outputs. Developing a forecast model is difficult, resource- and time-consuming. It is therefore worth asking what modelling is able to add beyond the subjective opinion of the researcher alone. To investigate this, we analysed different real-time forecasts of cases of and deaths from COVID-19 in Germany and Poland over a 1-4 week horizon submitted to the German and Polish Forecast Hub. We compared crowd forecasts elicited from researchers and volunteers, against a) forecasts from two semi-mechanistic models based on common epidemiological assumptions and b) the ensemble of all other models submitted to the Forecast Hub. We found crowd forecasts, despite being overconfident, to outperform all other methods across all forecast horizons when forecasting cases (weighted interval score relative to the Hub ensemble 2 weeks ahead: 0.89). Forecasts based on computational models performed comparably better when predicting deaths (rel. WIS 1.26), suggesting that epidemiological modelling and human judgement can complement each other in important ways.},
	author = {Bosse, Nikos and Abbott, Sam},
	year = {2021},
}

@article{yamana_superensemble_2016,
	title = {Superensemble forecasts of dengue outbreaks},
	volume = {13},
	issn = {1742-5689, 1742-5662},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2016.0410},
	doi = {10.1098/rsif.2016.0410},
	abstract = {In recent years, a number of systems capable of predicting future infectious disease incidence have been developed. As more of these systems are operationalized, it is important that the forecasts generated by these different approaches be formally reconciled so that individual forecast error and bias are reduced. Here we present a first example of such multi-system, or superensemble, forecast. We develop three distinct systems for predicting dengue, which are applied retrospectively to forecast outbreak characteristics in San Juan, Puerto Rico. We then use Bayesian averaging methods to combine the predictions from these systems and create superensemble forecasts. We demonstrate that on average, the superensemble approach produces more accurate forecasts than those made from any of the individual forecasting systems.},
	language = {en},
	number = {123},
	urldate = {2022-04-28},
	journal = {Journal of The Royal Society Interface},
	author = {Yamana, Teresa K. and Kandula, Sasikiran and Shaman, Jeffrey},
	month = oct,
	year = {2016},
	pages = {20160410},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\45JV4ZFG\\Yamana et al. - 2016 - Superensemble forecasts of dengue outbreaks.pdf:application/pdf},
}

@article{ray_prediction_2018,
	title = {Prediction of infectious disease epidemics via weighted density ensembles},
	volume = {14},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1005910},
	doi = {10.1371/journal.pcbi.1005910},
	language = {en},
	number = {2},
	urldate = {2022-05-03},
	journal = {PLOS Computational Biology},
	author = {Ray, Evan L. and Reich, Nicholas G.},
	editor = {Viboud, Cecile},
	month = feb,
	year = {2018},
	pages = {e1005910},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\WJX8W6WE\\Ray and Reich - 2018 - Prediction of infectious disease epidemics via wei.pdf:application/pdf},
}

@techreport{ray_ensemble_2020,
	type = {preprint},
	title = {Ensemble {Forecasts} of {Coronavirus} {Disease} 2019 ({COVID}-19) in the {U}.{S}.},
	url = {http://medrxiv.org/lookup/doi/10.1101/2020.08.19.20177493},
	abstract = {Abstract
          
            Background
            The COVID-19 pandemic has driven demand for forecasts to guide policy and planning. Previous research has suggested that combining forecasts from multiple models into a single “ensemble” forecast can increase the robustness of forecasts. Here we evaluate the real-time application of an open, collaborative ensemble to forecast deaths attributable to COVID-19 in the U.S.
          
          
            Methods
            Beginning on April 13, 2020, we collected and combined one- to four-week ahead forecasts of cumulative deaths for U.S. jurisdictions in standardized, probabilistic formats to generate real-time, publicly available ensemble forecasts. We evaluated the point prediction accuracy and calibration of these forecasts compared to reported deaths.
          
          
            Results
            Analysis of 2,512 ensemble forecasts made April 27 to July 20 with outcomes observed in the weeks ending May 23 through July 25, 2020 revealed precise short-term forecasts, with accuracy deteriorating at longer prediction horizons of up to four weeks. At all prediction horizons, the prediction intervals were well calibrated with 92-96\% of observations falling within the rounded 95\% prediction intervals.
          
          
            Conclusions
            This analysis demonstrates that real-time, publicly available ensemble forecasts issued in April-July 2020 provided robust short-term predictions of reported COVID-19 deaths in the United States. With the ongoing need for forecasts of impacts and resource needs for the COVID-19 response, the results underscore the importance of combining multiple probabilistic models and assessing forecast skill at different prediction horizons. Careful development, assessment, and communication of ensemble forecasts can provide reliable insight to public health decision makers.},
	language = {en},
	urldate = {2022-05-06},
	institution = {Epidemiology},
	author = {Ray, Evan L and Wattanachit, Nutcha and Niemi, Jarad and Kanji, Abdul Hannan and House, Katie and Cramer, Estee Y and Bracher, Johannes and Zheng, Andrew and Yamana, Teresa K and Xiong, Xinyue and Woody, Spencer and Wang, Yuanjia and Wang, Lily and Walraven, Robert L and Tomar, Vishal and Sherratt, Katharine and Sheldon, Daniel and Reiner, Robert C and Prakash, B. Aditya and Osthus, Dave and Li, Michael Lingzhi and Lee, Elizabeth C and Koyluoglu, Ugur and Keskinocak, Pinar and Gu, Youyang and Gu, Quanquan and George, Glover E. and España, Guido and Corsetti, Sabrina and Chhatwal, Jagpreet and Cavany, Sean and Biegel, Hannah and Ben-Nun, Michal and Walker, Jo and Slayton, Rachel and Lopez, Velma and Biggerstaff, Matthew and Johansson, Michael A and Reich, Nicholas G},
	month = aug,
	year = {2020},
	doi = {10.1101/2020.08.19.20177493},
	file = {Submitted Version:C\:\\Users\\rike\\Zotero\\storage\\MH7IEYX6\\Ray et al. - 2020 - Ensemble Forecasts of Coronavirus Disease 2019 (CO.pdf:application/pdf},
}

@article{zelner_accounting_2021,
	title = {Accounting for uncertainty during a pandemic},
	volume = {2},
	issn = {26663899},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666389921001537},
	doi = {10.1016/j.patter.2021.100310},
	language = {en},
	number = {8},
	urldate = {2022-05-09},
	journal = {Patterns},
	author = {Zelner, Jon and Riou, Julien and Etzioni, Ruth and Gelman, Andrew},
	month = aug,
	year = {2021},
	pages = {100310},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\7UE7AT6A\\Zelner et al. - 2021 - Accounting for uncertainty during a pandemic.pdf:application/pdf},
}

@article{james_use_2021,
	title = {The {Use} and {Misuse} of {Mathematical} {Modeling} for {Infectious} {Disease} {Policymaking}: {Lessons} for the {COVID}-19 {Pandemic}},
	volume = {41},
	issn = {0272-989X, 1552-681X},
	shorttitle = {The {Use} and {Misuse} of {Mathematical} {Modeling} for {Infectious} {Disease} {Policymaking}},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X21990391},
	doi = {10.1177/0272989X21990391},
	abstract = {Mathematical modeling has played a prominent and necessary role in the current coronavirus disease 2019 (COVID-19) pandemic, with an increasing number of models being developed to track and project the spread of the disease, as well as major decisions being made based on the results of these studies. A proliferation of models, often diverging widely in their projections, has been accompanied by criticism of the validity of modeled analyses and uncertainty as to when and to what extent results can be trusted. Drawing on examples from COVID-19 and other infectious diseases of global importance, we review key limitations of mathematical modeling as a tool for interpreting empirical data and informing individual and public decision making. We present several approaches that have been used to strengthen the validity of inferences drawn from these analyses, approaches that will enable better decision making in the current COVID-19 crisis and beyond.},
	language = {en},
	number = {4},
	urldate = {2022-05-11},
	journal = {Medical Decision Making},
	author = {James, Lyndon P. and Salomon, Joshua A. and Buckee, Caroline O. and Menzies, Nicolas A.},
	month = may,
	year = {2021},
	pages = {379--385},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\7GRPKBJ5\\James et al. - 2021 - The Use and Misuse of Mathematical Modeling for In.pdf:application/pdf},
}

@article{european_covid-19_forecast_hub_european_2021,
	title = {European {Covid}-19 {Forecast} {Hub}},
	volume = {covid19-forecast-hub-europe},
	url = {Available: https://github.com/covid19-forecast-hub-europe/covid19-forecast-hub-europe},
	author = {"European Covid-19 Forecast Hub"},
	year = {2021},
}

@article{ioannidis_forecasting_2022,
	title = {Forecasting for {COVID}-19 has failed},
	volume = {38},
	issn = {01692070},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207020301199},
	doi = {10.1016/j.ijforecast.2020.08.004},
	language = {en},
	number = {2},
	urldate = {2022-05-17},
	journal = {International Journal of Forecasting},
	author = {Ioannidis, John P.A. and Cripps, Sally and Tanner, Martin A.},
	month = apr,
	year = {2022},
	pages = {423--438},
}

@article{johansson_open_2019,
	title = {An open challenge to advance probabilistic forecasting for dengue epidemics},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1909865116},
	doi = {10.1073/pnas.1909865116},
	abstract = {A wide range of research has promised new tools for forecasting infectious disease dynamics, but little of that research is currently being applied in practice, because tools do not address key public health needs, do not produce probabilistic forecasts, have not been evaluated on external data, or do not provide sufficient forecast skill to be useful. We developed an open collaborative forecasting challenge to assess probabilistic forecasts for seasonal epidemics of dengue, a major global public health problem. Sixteen teams used a variety of methods and data to generate forecasts for 3 epidemiological targets (peak incidence, the week of the peak, and total incidence) over 8 dengue seasons in Iquitos, Peru and San Juan, Puerto Rico. Forecast skill was highly variable across teams and targets. While numerous forecasts showed high skill for midseason situational awareness, early season skill was low, and skill was generally lowest for high incidence seasons, those for which forecasts would be most valuable. A comparison of modeling approaches revealed that average forecast skill was lower for models including biologically meaningful data and mechanisms and that both multimodel and multiteam ensemble forecasts consistently outperformed individual model forecasts. Leveraging these insights, data, and the forecasting framework will be critical to improve forecast skill and the application of forecasts in real time for epidemic preparedness and response. Moreover, key components of this project—integration with public health needs, a common forecasting framework, shared and standardized data, and open participation—can help advance infectious disease forecasting beyond dengue.},
	language = {en},
	number = {48},
	urldate = {2022-06-10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Johansson, Michael A. and Apfeldorf, Karyn M. and Dobson, Scott and Devita, Jason and Buczak, Anna L. and Baugher, Benjamin and Moniz, Linda J. and Bagley, Thomas and Babin, Steven M. and Guven, Erhan and Yamana, Teresa K. and Shaman, Jeffrey and Moschou, Terry and Lothian, Nick and Lane, Aaron and Osborne, Grant and Jiang, Gao and Brooks, Logan C. and Farrow, David C. and Hyun, Sangwon and Tibshirani, Ryan J. and Rosenfeld, Roni and Lessler, Justin and Reich, Nicholas G. and Cummings, Derek A. T. and Lauer, Stephen A. and Moore, Sean M. and Clapham, Hannah E. and Lowe, Rachel and Bailey, Trevor C. and García-Díez, Markel and Carvalho, Marilia Sá and Rodó, Xavier and Sardar, Tridip and Paul, Richard and Ray, Evan L. and Sakrejda, Krzysztof and Brown, Alexandria C. and Meng, Xi and Osoba, Osonde and Vardavas, Raffaele and Manheim, David and Moore, Melinda and Rao, Dhananjai M. and Porco, Travis C. and Ackley, Sarah and Liu, Fengchen and Worden, Lee and Convertino, Matteo and Liu, Yang and Reddy, Abraham and Ortiz, Eloy and Rivero, Jorge and Brito, Humberto and Juarrero, Alicia and Johnson, Leah R. and Gramacy, Robert B. and Cohen, Jeremy M. and Mordecai, Erin A. and Murdock, Courtney C. and Rohr, Jason R. and Ryan, Sadie J. and Stewart-Ibarra, Anna M. and Weikel, Daniel P. and Jutla, Antarpreet and Khan, Rakibul and Poultney, Marissa and Colwell, Rita R. and Rivera-García, Brenda and Barker, Christopher M. and Bell, Jesse E. and Biggerstaff, Matthew and Swerdlow, David and Mier-y-Teran-Romero, Luis and Forshey, Brett M. and Trtanj, Juli and Asher, Jason and Clay, Matt and Margolis, Harold S. and Hebbeler, Andrew M. and George, Dylan and Chretien, Jean-Paul},
	month = nov,
	year = {2019},
	pages = {24268--24274},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\AL8DJ9WT\\Johansson et al. - 2019 - An open challenge to advance probabilistic forecas.pdf:application/pdf},
}

@incollection{timmermann_chapter_2006,
	title = {Chapter 4 {Forecast} {Combinations}},
	volume = {1},
	isbn = {978-0-444-51395-3},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574070605010049},
	language = {en},
	urldate = {2022-06-26},
	booktitle = {Handbook of {Economic} {Forecasting}},
	publisher = {Elsevier},
	author = {Timmermann, Allan},
	year = {2006},
	doi = {10.1016/S1574-0706(05)01004-9},
	pages = {135--196},
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	language = {en},
	number = {477},
	urldate = {2022-07-15},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E},
	month = mar,
	year = {2007},
	pages = {359--378},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\2U8M29I7\\Gneiting and Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Est.pdf:application/pdf},
}

@article{reich_collaborative_2022,
	title = {Collaborative {Hubs}: {Making} the {Most} of {Predictive} {Epidemic} {Modeling}},
	volume = {112},
	issn = {0090-0036, 1541-0048},
	shorttitle = {Collaborative {Hubs}},
	url = {https://ajph.aphapublications.org/doi/full/10.2105/AJPH.2022.306831},
	doi = {10.2105/AJPH.2022.306831},
	language = {en},
	number = {6},
	urldate = {2022-07-15},
	journal = {American Journal of Public Health},
	author = {Reich, Nicholas G. and Lessler, Justin and Funk, Sebastian and Viboud, Cecile and Vespignani, Alessandro and Tibshirani, Ryan J. and Shea, Katriona and Schienle, Melanie and Runge, Michael C. and Rosenfeld, Roni and Ray, Evan L. and Niehus, Rene and Johnson, Helen C. and Johansson, Michael A. and Hochheiser, Harry and Gardner, Lauren and Bracher, Johannes and Borchering, Rebecca K. and Biggerstaff, Matthew},
	month = jun,
	year = {2022},
	pages = {839--842},
}

@misc{bosse_epiforecastsscoringutils_2022,
	title = {epiforecasts/scoringutils: 1.0.0},
	copyright = {Open Access},
	shorttitle = {epiforecasts/scoringutils},
	url = {https://zenodo.org/record/4618017},
	abstract = {Major update to the package and most package functions with lots of breaking changes. Feature updates new and updated Readme and vignette the proposed scoring workflow was reworked. Functions were changed so they can easily be piped and have simplified arguments and outputs. new functions and function changes the function {\textless}code{\textgreater}eval\_forecasts(){\textless}/code{\textgreater} was replaced by a function {\textless}code{\textgreater}score(){\textless}/code{\textgreater} with a much reduced set of function arguments. Functionality to summarise scores and to add relative skill scores was moved to a function {\textless}code{\textgreater}summarise\_scores(){\textless}/code{\textgreater} new function {\textless}code{\textgreater}check\_forecasts(){\textless}/code{\textgreater} to analyse input data before scoring new function {\textless}code{\textgreater}correlation(){\textless}/code{\textgreater} to compute correlations between different metrics new function {\textless}code{\textgreater}add\_coverage(){\textless}/code{\textgreater} to add coverage for specific central prediction intervals new function {\textless}code{\textgreater}avail\_forecasts(){\textless}/code{\textgreater} allows to visualise the number of available forecasts new function {\textless}code{\textgreater}find\_duplicates(){\textless}/code{\textgreater} to find duplicate forecasts which cause an error all plotting functions were renamed to begin with {\textless}code{\textgreater}plot\_{\textless}/code{\textgreater}. Arguments were simplified the function {\textless}code{\textgreater}pit(){\textless}/code{\textgreater} now works based on data.frames. The old {\textless}code{\textgreater}pit{\textless}/code{\textgreater} function was renamed to {\textless}code{\textgreater}pit\_sample(){\textless}/code{\textgreater}. PIT p-values were removed entirely. the function {\textless}code{\textgreater}plot\_pit(){\textless}/code{\textgreater} now works directly with input as produced by {\textless}code{\textgreater}pit(){\textless}/code{\textgreater} many data-handling functions were removed and input types for {\textless}code{\textgreater}score(){\textless}/code{\textgreater} were restricted to sample-based, quantile-based or binary forecasts. the function {\textless}code{\textgreater}brier\_score(){\textless}/code{\textgreater} now returns all brier scores, rather than taking the mean before returning an output. {\textless}code{\textgreater}crps{\textless}/code{\textgreater}, {\textless}code{\textgreater}dss{\textless}/code{\textgreater} and {\textless}code{\textgreater}logs{\textless}/code{\textgreater} were renamed to {\textless}code{\textgreater}crps\_sample(){\textless}/code{\textgreater}, {\textless}code{\textgreater}dss\_sample(){\textless}/code{\textgreater}, and {\textless}code{\textgreater}logs\_sample(){\textless}/code{\textgreater} Bug fixes Testing was expanded minor bugs were fixed, for example a bug in the sample\_to\_quantile function (https://github.com/epiforecasts/scoringutils/pull/223) package data updated package data is now based on forecasts submitted to the European Forecast Hub (https://covid19forecasthub.eu/). all example data files were renamed to begin with {\textless}code{\textgreater}example\_{\textless}/code{\textgreater} a new data set, {\textless}code{\textgreater}summary\_metrics{\textless}/code{\textgreater} was included that contains a summary of the metrics implemented in {\textless}code{\textgreater}scoringutils{\textless}/code{\textgreater} Other breaking changes The 'sharpness' component of the weighted interval score was renamed to dispersion. This was done to make it more clear what the component represents and to maintain consistency with what is used in other places.},
	urldate = {2022-08-01},
	publisher = {Zenodo},
	author = {Bosse, Nikos and Abbott, Sam and Gruson, Hugo and Funk, Sebastian and Reich, Nicholas G},
	month = may,
	year = {2022},
	doi = {10.5281/ZENODO.4618017},
}

@article{bosse_evaluating_2022,
	title = {Evaluating {Forecasts} with scoringutils in {R}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2205.07090},
	doi = {10.48550/ARXIV.2205.07090},
	abstract = {Evaluating forecasts is essential in order to understand and improve forecasting and make forecasts useful to decision-makers. Much theoretical work has been done on the development of proper scoring rules and other scoring metrics that can help evaluate forecasts. In practice, however, conducting a forecast evaluation and comparison of different forecasters remains challenging. In this paper we introduce scoringutils, an R package that aims to greatly facilitate this process. It is especially geared towards comparing multiple forecasters, regardless of how forecasts were created, and visualising results. The package is able to handle missing forecasts and is the first R package to offer extensive support for forecasts represented through predictive quantiles, a format used by several collaborative ensemble forecasting efforts. The paper gives a short introduction to forecast evaluation, discusses the metrics implemented in scoringutils and gives guidance on when they are appropriate to use, and illustrates the application of the package using example data of forecasts for COVID-19 cases and deaths submitted to the European Forecast Hub between May and September 2021},
	urldate = {2022-08-01},
	author = {Bosse, Nikos I. and Gruson, Hugo and Cori, Anne and van Leeuwen, Edwin and Funk, Sebastian and Abbott, Sam},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {Applications (stat.AP), Computation (stat.CO), FOS: Computer and information sciences, Methodology (stat.ME)},
}

@article{moran_epidemic_2016,
	title = {Epidemic {Forecasting} is {Messier} {Than} {Weather} {Forecasting}: {The} {Role} of {Human} {Behavior} and {Internet} {Data} {Streams} in {Epidemic} {Forecast}},
	volume = {214},
	issn = {0022-1899, 1537-6613},
	shorttitle = {Epidemic {Forecasting} is {Messier} {Than} {Weather} {Forecasting}},
	url = {https://academic.oup.com/jid/article-lookup/doi/10.1093/infdis/jiw375},
	doi = {10.1093/infdis/jiw375},
	language = {en},
	number = {suppl 4},
	urldate = {2022-08-03},
	journal = {Journal of Infectious Diseases},
	author = {Moran, Kelly R. and Fairchild, Geoffrey and Generous, Nicholas and Hickmann, Kyle and Osthus, Dave and Priedhorsky, Reid and Hyman, James and Del Valle, Sara Y.},
	month = dec,
	year = {2016},
	pages = {S404--S408},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\C7DIS4M3\\Moran et al. - 2016 - Epidemic Forecasting is Messier Than Weather Forec.pdf:application/pdf},
}

@article{jajosky_evaluation_2004,
	title = {Evaluation of reporting timeliness of public health surveillance systems for infectious diseases},
	volume = {4},
	issn = {1471-2458},
	url = {http://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-4-29},
	doi = {10.1186/1471-2458-4-29},
	language = {en},
	number = {1},
	urldate = {2022-08-03},
	journal = {BMC Public Health},
	author = {Jajosky, Ruth Ann and Groseclose, Samuel L},
	month = dec,
	year = {2004},
	pages = {29},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\VTBHMV69\\Jajosky and Groseclose - 2004 - Evaluation of reporting timeliness of public healt.pdf:application/pdf},
}

@misc{brooks_comparing_2020,
	title = {Comparing ensemble approaches for short-term probabilistic {COVID}-19 forecasts in the {U}.{S}.},
	url = {https://forecasters.org/blog/2020/10/28/comparing-ensemble-approaches-for-short-term-probabilistic-covid-19-forecasts-in-the-u-s/},
	urldate = {2022-07-15},
	journal = {International Institute of Forecasters},
	author = {Brooks, Logan C. and Ray, Evan L. and Bien, Jacob and Bracher, Johannes and Rumack, Aaron and Tibshirani, Ryan J. and Reich, Nicholas G.},
	year = {2020},
}

@misc{ray_challenges_2021,
	title = {Challenges in training ensembles to forecast {COVID}-19 cases and deaths in the {United} {States}},
	url = {https://forecasters.org/blog/2021/04/09/challenges-in-training-ensembles-to-forecast-covid-19-cases-and-deaths-in-the-united-states/},
	urldate = {2022-07-15},
	journal = {International Institute of Forecasters},
	author = {Ray, Evan L. and Brooks, Logan C. and Bien, Jacob and Bracher, Johannes and Gerding, Aaron and Rumack, Aaron and Biggerstaff, Matthew and Johansson, Michael A. and Tibshirani, Ryan J. and Reich, Nicholas G.},
	year = {2021},
}

@misc{bracher_national_2021,
	type = {preprint},
	title = {National and subnational short-term forecasting of {COVID}-19 in {Germany} and {Poland}, early 2021},
	url = {http://medrxiv.org/lookup/doi/10.1101/2021.11.05.21265810},
	abstract = {Abstract
          We report on the second and final part of a pre-registered forecasting study on COVID-19 cases and deaths in Germany and Poland. Fifteen independent research teams provided forecasts at lead times of one through four weeks from January through mid-April 2021. Compared to the first part (October–December 2020), the number of participating teams increased, and a number of teams started providing subnational-level forecasts. The addressed time period is characterized by rather stable non-pharmaceutical interventions in both countries, making short-term predictions more straightforward than in the first part of our study. In both countries, case counts declined initially, before rebounding due to the rise of the B.1.1.7 variant. Deaths declined through most of the study period in Germany while in Poland they increased after a prolonged plateau. Many, though not all, models outperformed a simple baseline model up to four weeks ahead, with ensemble methods showing very good relative performance. Major trend changes in reported cases, however, remained challenging to predict.},
	language = {en},
	urldate = {2022-08-09},
	publisher = {Epidemiology},
	author = {Bracher, J. and Wolffram, D. and Deuschel, J. and Görgen, K. and Ketterer, J.L. and Ullrich, A. and Abbott, S. and Barbarossa, M.V. and Bertsimas, D. and Bhatia, S. and Bodych, M. and Bosse, N.I. and Burgard, J.P. and Fiedler, J. and Fuhrmann, J. and Funk, S. and Gambin, A. and Gogolewski, K. and Heyder, S. and Hotz, T. and Kheifetz, Y. and Kirsten, H. and Krueger, T. and Krymova, E. and Leithäuser, N. and Li, M.L. and Meinke, J.H. and Miasojedow, B. and Mohring, J. and Nouvellet, P. and Nowosielski, J.M. and Ozanski, T. and Radwan, M. and Rakowski, F. and Scholz, M. and Soni, S. and Srivastava, A. and Gneiting, T. and Schienle, M.},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.05.21265810},
	file = {Submitted Version:C\:\\Users\\rike\\Zotero\\storage\\9VW58ANB\\Bracher et al. - 2021 - National and subnational short-term forecasting of.pdf:application/pdf},
}

@article{noauthor_notitle_nodate,
}

@misc{sherratt_predictive_2022,
	title = {Predictive performance of multi-model ensemble forecasts of {COVID}-19 across {European} nations},
	url = {https://www.medrxiv.org/content/10.1101/2022.06.16.22276024v1.full.pdf},
	author = {Sherratt, Katharine and Gruson, Hugo},
	year = {2022},
}

@techreport{cramer_united_2021,
	type = {preprint},
	title = {The {United} {States} {COVID}-19 {Forecast} {Hub} dataset},
	url = {http://medrxiv.org/lookup/doi/10.1101/2021.11.04.21265886},
	abstract = {Abstract
          Academic researchers, government agencies, industry groups, and individuals have produced forecasts at an unprecedented scale during the COVID-19 pandemic. To leverage these forecasts, the United States Centers for Disease Control and Prevention (CDC) partnered with an academic research lab at the University of Massachusetts Amherst to create the US COVID-19 Forecast Hub. Launched in April 2020, the Forecast Hub is a dataset with point and probabilistic forecasts of incident hospitalizations, incident cases, incident deaths, and cumulative deaths due to COVID-19 at national, state, and county levels in the United States. Included forecasts represent a variety of modeling approaches, data sources, and assumptions regarding the spread of COVID-19. The goal of this dataset is to establish a standardized and comparable set of short-term forecasts from modeling teams. These data can be used to develop ensemble models, communicate forecasts to the public, create visualizations, compare models, and inform policies regarding COVID-19 mitigation. These open-source data are available via download from GitHub, through an online API, and through R packages.},
	language = {en},
	urldate = {2022-08-09},
	institution = {Epidemiology},
	author = {Cramer, Estee Y and Huang, Yuxin and Wang, Yijin and Ray, Evan L and Cornell, Matthew and Bracher, Johannes and Brennen, Andrea and Castero Rivadeneira, Alvaro J and Gerding, Aaron and House, Katie and Jayawardena, Dasuni and Kanji, Abdul H and Khandelwal, Ayush and Le, Khoa and Niemi, Jarad and Stark, Ariane and Shah, Apurv and Wattanchit, Nutcha and Zorn, Martha W and Reich, Nicholas G},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.04.21265886},
	file = {Accepted Version:C\:\\Users\\rike\\Zotero\\storage\\SQEPAR5H\\Cramer et al. - 2021 - The United States COVID-19 Forecast Hub dataset.pdf:application/pdf},
}

@misc{bracher_german_2020,
	title = {The {German} and {Polish} {COVID}-19 {Forecast} {Hub}},
	url = {https://github.com/KITmetricslab/covid19-forecast-hub-de},
	author = {Bracher, Johannes and Wolffram, Daniel and Deuschel, Jannik and Görgen, Konstantin and Ketterer, Jakob and Gneiting, Tilmann and Schienle, Melanie},
	year = {2020},
}

@incollection{brauer_epidemic_2012,
	address = {New York, NY},
	title = {Epidemic {Models}},
	volume = {40},
	isbn = {978-1-4614-1685-2 978-1-4614-1686-9},
	url = {http://link.springer.com/10.1007/978-1-4614-1686-9_9},
	language = {en},
	urldate = {2022-08-10},
	booktitle = {Mathematical {Models} in {Population} {Biology} and {Epidemiology}},
	publisher = {Springer New York},
	author = {Brauer, Fred and Castillo-Chavez, Carlos},
	collaborator = {Brauer, Fred and Castillo-Chavez, Carlos},
	year = {2012},
	doi = {10.1007/978-1-4614-1686-9_9},
	note = {Series Title: Texts in Applied Mathematics},
	pages = {345--409},
	file = {Full Text:C\:\\Users\\rike\\Zotero\\storage\\NVANRA9T\\Brauer and Castillo-Chavez - 2012 - Epidemic Models.pdf:application/pdf},
}

@misc{noauthor_notitle_nodate-1,
}

@misc{abbott_epinow2_2020,
	title = {{EpiNow2}: {Estimate} {Real}-{Time} {Case} {Counts} and {Time}-{Varying} {Epidemiological} {Parameters}},
	author = {Abbott, Sam and Hellewell, Joel and Sherratt, Katharine and Gostic, Katelyn and Hickson, Joe and Badr, Hamada S. and DeWitt, Michael and Thompson, Robin and {EpiForecasts} and Funk, Sebastian},
	year = {2020},
	doi = {10.5281/zenodo.3957489},
}

@article{claeskens_forecast_2016,
	title = {The forecast combination puzzle: {A} simple theoretical explanation},
	volume = {32},
	issn = {01692070},
	shorttitle = {The forecast combination puzzle},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207016000327},
	doi = {10.1016/j.ijforecast.2015.12.005},
	language = {en},
	number = {3},
	urldate = {2022-08-11},
	journal = {International Journal of Forecasting},
	author = {Claeskens, Gerda and Magnus, Jan R. and Vasnev, Andrey L. and Wang, Wendun},
	month = jul,
	year = {2016},
	pages = {754--762},
	file = {Accepted Version:C\:\\Users\\rike\\Zotero\\storage\\HG69KPH8\\Claeskens et al. - 2016 - The forecast combination puzzle A simple theoreti.pdf:application/pdf},
}

@misc{sherratt_european_2022,
	title = {European {Covid}-19 {Forecast} {Hub}},
	url = {https://doi.org/10.5281/zenodo.6962430},
	author = {Sherratt, Katharine and Gruson, Hugo and Johnson, Helen and Niehus, Rene and Prasse, Bastian and Sandman, Frank and Deuschel, Jannik and Wolffram, Daniel and Abbott, Sam and Ullrich, Alexander and Gibson, Graham and Ray, Evan L. and Reich, Nicholas G. and Sheldon, Daniel and Wang, Yijin and Wattanachit, Nutcha and Wang, Lijing and Trnka, Jan and Obozinski, Guillaume and Sun, Tao and Thanou, Dorina and Pottier, Loic and Krymova, Ekaterina and Barbarossa, Maria Vittoria and Leithauser, Neele and Mohring, Jan and Schneider, Johanna and Wlazlo, Jaroslaw and Fuhrmann, Jan and Lange, Berit and Rodiah, Isti and Baccam, Prasith and Gurung, Heidi and Stage, Steven and Suchoski, Bradley and Budzinski, Jozef and Walraven, Robert and Villanueva, Inmaculada and Tucek, Vit and Smid, Martin and Zajicek, Milan and Alvarez, Cesar Perez and Reina, Borja and Bosse, Nikos I. and Meakin, Sophie and Loro, Pierfrancesco Alaimo Di and Maruotti, Antonello and Eclerova, Veronika and Kraus, Andrea and Kraus, David and Pribylova, Lenka and Dimitris, Bertsimas and Li, Michael Lingzhi and Saksham, Soni and Dehning, Jonas and Mohr, Sebastian and Priesemann, Viola and Redlarski, Grzegorz and Bejar, Benjamin and Ardenghi, Giovanni and Parolini, Nicola and Ziarelli, Giovanni and Bock, Wolfgang and Heyder, Stefan and Hotz, Thomas and Singh, David E. and Guzman-Merino, Miguel and Aznarte, Jose L. and Morina, David and Alonso, Sergio and Alvarez, Enric and Lopez, Daniel and Prats, Clara and Burgard, Jan Pablo and Rodloff, Arne and Zimmermann, Tom and Kuhlmann, Alexander and Zibert, Janez and Pennoni, Fulvia and Divino, Fabio and Catala, Marti and Lovison, Gianfranco and Giudici, Paolo and Tarantino, Barbara and Bartolucci, Francesco and Lasinio, Giovanna Jona and Mingione, Marco and Farcomeni, Alessio and Srivastava, Ajitesh and Montero-Manso, Pablo and Adiga, Aniruddha and Hurt, Benjamin and Lewis, Bryan and Marathe, Madhav and Porebski, Przemyslaw and Venkatramanan, Srinivasan and Bartczuk, Rafal and Dreger, Filip and Gambin, Anna and Gogolewski, Krzysztof and Gruziel-Slomka, Magdalena and Krupa, Bartosz and Moszynski, Antoni and Niedzielewski, Karol and Nowosielski, Jedrzej and Radwan, Maciej and Rakowski, Franciszek and Semeniuk, Marcin and Szczurek, Ewa and Zielinski, Jakub and Kisielewski, Jan and Pabjan, Barbara and Holger, Kirsten and Kheifetz, Yuri and Scholz, Markus and Bodych, Marcin and Filinski, Maciej and Idzikowski, Radoslaw and Krueger, Tyll and Ozanski, Tomasz and Bracher, Johannes and Funk, Sebastian},
	month = aug,
	year = {2022},
	note = {Publisher: Zenodo
Version Number: v2022.08.04},
}

@article{diebold_comparing_1995,
	title = {Comparing {Predictive} {Accuracy}},
	volume = {13},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07350015.1995.10524599},
	doi = {10.1080/07350015.1995.10524599},
	language = {en},
	number = {3},
	urldate = {2022-08-17},
	journal = {Journal of Business \& Economic Statistics},
	author = {Diebold, Francis X. and Mariano, Roberto S.},
	month = jul,
	year = {1995},
	pages = {253--263},
	file = {Submitted Version:C\:\\Users\\rike\\Zotero\\storage\\GLX5M8E8\\Diebold and Mariano - 1995 - Comparing Predictive Accuracy.pdf:application/pdf},
}
